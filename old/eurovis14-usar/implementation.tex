\section{Implementation} \label{sec:implementation}

In this section, we will describe the details necessary to reproduce this work. We used the OpenMP framework~\cite{660313} for most of the preprocessing and path computation and achieved a speedup that is very close to linear.

\noindent {\bfseries Data Preprocessing.} The input data for this step is the acquired and co-registered point cloud from the autonomous robots. Each point in the point cloud stores its position in a global coordinate system as well as additional information, for example a color value or results from other scanners. Based on this data the voxel binning and filtering is performed. A user-defined voxel size in standard units is prescribed and the points of the point cloud are assigned to their closest voxel center. The number of points per voxel is the occupancy, as in Section~\ref{sec:overview:precomputation}. The filtering step removes all voxels with an occupancy below a defined threshold; in our case $1$. This generates a second point cloud containing only the valid voxel centers. In a following step all necessary fields are computed for the voxel point cloud, like normals, size restrictions or support. These operations are done in parallel for each voxel and do not require any intercommunication, thus making the parallelization near-optimal. For the Fukushima dataset with 35 million points, the full precomputation takes between one and two minutes on a four core machine.

\noindent {\bfseries Rendering.} The 3D rendering is performed on the preprocessed point cloud using OpenGL 4. The positions of the occupied voxel centers are stored in a vertex buffer object and rendered with a single \texttt{glDrawArrays} command. The different fields~(Figure~\ref{fig:overview:precomputation}) are stored in VBOs and attached as vertex attributes. The vertex shader performs packing of these values to increase the performance when the vertices are pushed through the pipeline. Although this operation reduces the dynamic range for the fields to 8 bits, the visual difference is minimal. As the size of the binning is known, a geometry shader constructs the vertices for an axis-aligned bounding box around each center, thus rendering the front faces of the boxes without the need for additional storage on the GPU. With all optimizations we achieve frame rates of at least $20$fps for our datasets.

\noindent {\bfseries Path Computation.} As described in Section~\ref{sec:overview:path} we use the A* algorithm with our composite metric $m$ to generate an ensemble of paths. The four weights $w_{h,n,s,sup}$ and two values $angle$ and $n$ in the metric span a six-dimensional parameter space. We sample this space on a regular grid and compute a path for each parameter configuration. High parallelism is possible as all paths are computed independently of one another. For each path the fields are calculated and stored alongside an ordered list of voxels that path passes through. For each voxel, the submetric decision criteria are stored as well. In our experiments we sampled the parameter space at $\approx 10^5$ positions and the computations required about a minute on a four core machine with $3$GHz. With respect to the parallelism an increase in cores will lead to a linear decrease in computation time. 